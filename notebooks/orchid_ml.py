# For progress display in ipython notebook
from IPython.core.display import clear_output
from IPython.display import clear_output

import sys, os, datetime, time
from random import shuffle
from collections import defaultdict

# Data visualization
import numpy as np
import pandas as pd
import seaborn as sns
import inspect as inspect
import matplotlib.pyplot as plt
from matplotlib.colors import rgb2hex, hex2color
from matplotlib.pylab import cm


# Scikit learn stuff
from sklearn import svm, linear_model                                                                    # SVM and linear models
from copy import deepcopy                                                                                # To duplicate models
from sklearn.externals import joblib                                                                     # To save jobs
from sklearn.ensemble import RandomForestClassifier                                                      # Random Forest model
from sklearn.multiclass import OneVsRestClassifier                                                       # For multi class problems
from sklearn.neighbors import LSHForest
from sklearn.preprocessing import *
from sklearn.model_selection import *                                                                    # Cross validation, parameter tuning
from sklearn.metrics import *                                                                            # To assess model performance
from sklearn.base import clone 


# Other category encoders
import category_encoders as ce

from scipy import interp
from urlparse import urlparse
import json
import dill


class MutationMatrix(pd.DataFrame):
    "Some cancer mutation and machine learning extensions for the pandas DataFrame"

    _metadata          = [
                          'chunk_size', 'db_uri', 'db_metadata', 'mutation_table', 'mutation_table_id', 'mutation_id_column', 'donor_id_column', 'annotation_columns', 'feature_categories', 'features', 
                          'label_column', 'quiet', 'mutations_loaded', 'features_loaded', 'encoded', 'collapsed', 'normalized', 'imputer', 'scaler', 'model', 'le', 'train_ids', 'X_train', 'X_test', 
                          'Y_train', 'Y_test', 'Y_probabilities', 'Y_predictions', 'cv_used', 'cv_usage', 'normalize_options', 'number_cpus'
                         ]
    
    chunk_size         = 10000
    db_uri             = None
    db_metadata        = None
    mutation_table     = None
    mutation_table_id  = None  # 
    mutation_id_column = 'mutation_id'
    donor_id_column    = 'donor_id'
    label_column       = None
    annotation_columns = None
    feature_categories = None
    features           = None
    feature_transforms = {}
    quiet              = False
    mutations_loaded   = False    # Whether mutation data has been loaded
    features_loaded    = False    # Whether features have been loaded
    encoded            = False    # Whether features have been encoded
    collapsed          = False    # Whether this MutationMatrix has been collapsed
    normalized         = False    # Whether this MutationMatrix has been normalized
    imputer            = None     # The imputer used to normalize this MutationMatrix
    scaler             = None     # The scaler used to normalize this MutationMatrix
    model              = None     # The model used to train data
    le                 = None     # The label encoder used to convert label_column labels to numeric indices 
    train_ids          = None     # The ssm ids used for training
    X_train            = None     # The training examples
    X_test             = None     # The testing examples or None when cross-validating
    Y_train            = None     # The corresponding training labels
    Y_test             = None     # The corresponding testing labels or None when cross-validating
    Y_probabilities    = None     # The test probabilities generated by the model
    Y_predictions      = None     # The test predictions generated by the model
    cv_used            = False    # Whether cross validation was used to generate predictions
    cv_usage           = None     # The indices of training data used for each fold 

    normalize_options  = {
                           'nan_strat'      : 'median',
                           'scaler_strat'   : 'standard',
                         }
    number_cpus        = -1


    @property
    def _constructor(self):
        return MutationMatrix
    
    @property
    def _constructor_sliced(self):
        return pd.Series

    # Some data, and/or metadata
    # TODO: Add column populator
    def __init__(self, *args, **kwargs):
        """ initialize the MutationMatrix """
        self.db_uri   = kwargs.pop('db_uri', None)
        self.quiet    = kwargs.pop('quiet', False)
        super(MutationMatrix, self).__init__(*args, **kwargs)

    def __finalize__(self, other, method=None, **kwargs):
        """ propagate metadata from other to self """
        # merge operation: using metadata of the left object
        if method == 'merge':
            for name in self._metadata:
                object.__setattr__(self, name, getattr(other.left, name, None))
        # concat operation: using metadata of the first object
        elif method == 'concat':
            for name in self._metadata:
                object.__setattr__(self, name, getattr(other.objs[0], name, None))
        else:
            for name in self._metadata:
                object.__setattr__(self, name, getattr(other, name, None))
        return self

    def __getitem__(self, key):
        """ get a MutationMatrix property """
        """ BUGFIX: Series generated from MutationMatrix retain old values, so force pd.Series to flush cache """
        self._clear_item_cache()
        result = super(MutationMatrix, self).__getitem__(key)
        result._clear_item_cache()
        result = super(MutationMatrix, self).__getitem__(key)
        return result


    def set_backing_database(self, db_uri):
        """ set the backing database for which the MutationMatrix loads data """
        self.db_uri = db_uri
        self.load_metadata()


    def load_metadata(self):
        """ load metadata (features, table names, etc) provided by orchid_db into the MutationMatrix """
        ## db_uri
        if self.db_uri==None:
            print "Please select a database using set_backing_database(database_uri). Metadata will then be automatically loaded."
            return
        self.db_metadata = {}
        syntax = "SELECT metavalue FROM metadata WHERE metakey='features'"
        features = pd.read_sql(syntax, self.db_uri)['metavalue'][0]
        features = json.loads(features)
        self.db_metadata['features'] = features
        self.features = pd.Series(features.keys())
        syntax = "SELECT metavalue FROM metadata WHERE metakey='params'"
        params = pd.read_sql(syntax, self.db_uri)['metavalue'][0]
        params = json.loads(params)
        self.db_metadata['params'] = params
        self.mutation_table = params['mutation_table']
        self.mutation_table_id = params['mutation_table']+"_id"
        return


    def set_features(self, feature_list=None, drop_others=True):
        """
        Set the features of this MutationMatrix (stored as a Pandas Index). These features will be used to predict the label classes when modeling.

        Arguments:
        feature_list (optional): A list of column names in the MutationMatrix to designate as model features.
        drop_others (optional): Whether to drop other features
        """
        if type(feature_list)!=type(None):
            self.features = pd.Index(list(feature_list))
        else:
            self.features = pd.Index(set(self.columns) - set(self.annotation_columns) - set([self.label_column]))
            drop_others = False
        if drop_others:
            to_keep = pd.Index(list(self.annotation_columns) + list(self.features) + list([self.label_column])).dropna()
            self._data = self[to_keep]._data


    def add_meta(self, meta):
        """
        Adds metadata columns to the MutationMatrix. 

        Arguments:
        meta (required): a dataframe with one or more metadata columns and a column or index that match the MutationMatrix index or column for merging.
        """
        index       = self.index.name
        meta        = meta.reset_index()
        mutations   = self.reset_index()
        cols_to_use = meta.columns.difference(mutations.columns)
        if not any(meta.columns.isin(mutations.columns)):
            print "You must provide a common column to merge on the metadata to the MutationMatrix."
            return
        else:
            common = meta.columns.intersection(mutations.columns)[0]
            mutations  = mutations.merge(meta, how='left', left_on=common, right_on=common)
            if 'index' in mutations.columns:
                mutations = mutations.drop('index', axis=1)
            self._data   = mutations.set_index(index)._data


    def add_labels(self, mapping):
        """
        Adds a label column to the MutationMatrix. Labels are the classes used for supervised learning.

        Arguments:
        mapping (required): a dataframe with two columns: 1) column label and values that match the MutationMatrix, and 2) A column of values to merge into the MutationMatrix.
        """
        mapping_columns = set(pd.DataFrame(mapping).columns)
        label_column = mapping_columns.difference(set(list(self.columns)+[self.index.name]))
        if len(label_column)==0:
            print "It appears the label column has already been added."
            return
        if len(label_column)>1:
            print "To add a label column to the MutationMatrix, you must provide a dataframe with two columns: 1) column label and values that match the MutationMatrix, and 2) A column of values to merge into the MutationMatrix."
            return
        anchor_column = list(mapping_columns.difference(label_column))[0]
        label_column  = list(label_column)[0]
        if anchor_column == self.index.name:
            self._data = pd.DataFrame(self.merge(mapping, how='left', left_index=True, right_on=anchor_column).drop(anchor_column,1))._data
        else:
            self._data = pd.DataFrame(self.merge(mapping, how='left', left_on=anchor_column, right_on=anchor_column))._data
        self.label_column = label_column


    def set_label_column(self, col_name):
        """
        Set the label column, that is, which column should be predicted.
        NOTE: Is a feature column is specified as the label it will be removed from the feature list if present.

        Arguments:
        col_name (required): The name of a column in the MutationMatrix to use for the label. It can be a feature column.
        """
        # First, check to see if the column exists
        if col_name not in self.columns:
            print "You must specify a column label that exists in the MutationMatrix, or merge a label column into the MutationMatrix using add_labels()."
            return
        # Check to see if there are at least 2 columns.
        num_values = len(self[col_name].value_counts())
        if num_values < 2:
            print "This label column has less than 2 unique values and can't be used for prediction."
            return
        if col_name in self.features:
            self.features = self.features.drop(col_name)
        self.label_column = col_name


    def set_normalize_options(self, nan_strat='zero', scaler_strat='mms'):
        """
        Set the normalization options for data.

        Arguments:
        nan_strat (optional; zero): The strategy for handling NaN values. Options are 'zero' for replacing NaNs with 0, 'median' with the column median value, or 'mean' with the column mean value.
        scaler_strat (optional; mms): The strategy for handling feature scaling. Options are 'standard' for a z-score method, or 'mms' for a min/max scaler. Other sklearn methods can also be used.
        """
        self.normalize_options = {
                                   'nan_strat'    :  nan_strat,
                                   'scaler_strat' :  scaler_strat,
                                 }


    # Takes a peek at the MutationMatrix, taking half of the requested rows from the top and bottom
    def peek(self, size=1000):
        X = self.as_matrix()
        subset = X if np.shape(X)[0] < size else X[range(0,int(size/2.))+range(-int(size/2.),-1),:]
        ax = sns.heatmap(pd.DataFrame(subset), yticklabels=False, xticklabels=False, cmap="Blues")


    def load(self, *args, **kwargs):
        """
        A method to load mutations and features in one step.
        """
        self.load_mutations(*args, **kwargs)
        self.load_features(*args, **kwargs)


    def load_mutations(self, ids=None, by='donor', number_real='all', number_simulated=None, quiet=None, *args, **kwargs):
        """
        This function will load mutation information from the database, and optionally simulated data produced by orchid. 
        
        Arguments:
        ids (optional; None): The list of ids for samples that correspond to the "by" column to load.
        by (optional; donor): If "ids" are provided, "by" is the column whose values determine which samples to load. Can be either "donor" or "mutation".
        number_real (optional; 'all'): The number of real samples to load. This can be either a positive integer or 'all' to load all real samples. If specifying a number, n, and n is less than the number of real samples, samples will be randomly selected. 
        number_simulated (optional; None): If orchid was used to generated simulated data, the number of simulated samples to load. Options are:
                                           "max" -- equal to the number of mutations for the donor with the most mutations,
                                           "average" -- equal to the average number of mutations across donors, 
                                           "equal" -- equal to the total number of mutations,
                                           "all" -- load all simulated mutations in the database, or 
                                           None -- don't load any simulated mutations. 
        quiet (optional; None): Whether to be verbose in output or not. Defaults to the MutationMatrix set "quiet" parameter. 
        """
        # Check input
        quiet = self.quiet if quiet==None else quiet
        ## db_uri
        if self.db_uri==None:
            print "Plese select a database using the set_backing_database(database_uri) method."
            return
        ## number_real
        if (number_real==None) or ((type(number_real)==int) and (number_real<1)):
            print "You must request at least 1 real mutation"
        elif (type(number_real)!=int) and (number_real!='all'):
            print "number_real must be either a positive integer or 'all'."
            return
        ## number_simulated
        if number_simulated==None:
            pass
        elif type(number_simulated) == int and number_simulated < 1:
            print "You must request a positive number of simulated mutations."
            return
        elif type(number_simulated) == str:
                if number_simulated not in ('max', 'average', 'equal', 'all'):
                    print "If specifying the number of simulated mutations as text, use 'max', 'average', 'equal', or 'all'."
                    return
        ## by
        if by not in ('donor', 'mutation'):
            print "Mutation information can only be loaded by donor or mutation ids at this time."
            return
        ## ids
        if not (ids is None or (type(ids) == list and all([type(a) == str for a in ids])) or type(ids) == str):
            print "'ids' must be either a single value (string), a list of donor or mutation ids (strings), or 'None' to load all mutations from the database."
            return

        if by=='donor':
            by = self.donor_id_column
        else:
            by = self.mutation_id_column

        # Load metadata
        if not quiet: print "Loading database metadata"
        self.load_metadata()

        # Get the real mutations
        real_mutations = None
        if number_real == 'all':
            syntax = "SELECT * FROM %s WHERE is_simulated=0" % self.mutation_table
            if ids:
                syntax += " AND %s IN ('%s')" % (by, "', '".join([str(a) for a in ids]))
                if not quiet: print "Getting [%s] real mutations for the requested %ss..." % (str(number_real), by)
                sys.stdout.flush()
            else:
                if not quiet: print "Getting [all] real mutations..." 
            real_mutations = pd.read_sql(syntax, self.db_uri)
            number_real = real_mutations.shape[0]
        else:
            syntax = "SELECT %s FROM %s WHERE is_simulated=0" % (self.mutation_table_id, self.mutation_table)
            if ids:
                syntax += " AND %s IN ('%s')" % (by, "', '".join([str(a) for a in ids]))
            # Get the mutations
            if not quiet: print "Getting [%s] real mutations... (randomly sampled)" % str(number_real)
            real_ids = pd.read_sql(syntax, self.db_uri)
            # Sample the number of requested
            replace = False
            if len(real_ids) < number_real:
                if not quiet: print "Fewer possible real mutations than requested, sampling with replacement..."
                replace = True
            real_ids = real_ids.sample(number_real, replace=replace)
            syntax = "SELECT * FROM %s WHERE %s IN (%s)" % (self.mutation_table, self.mutation_table_id, ", ".join([str(a) for a in list(real_ids[self.mutation_table_id])]))
            real_mutations = pd.read_sql(syntax, self.db_uri)

        # Get simulated mutations if requested
        sim_mutations = None
        if number_simulated != None:
            if number_simulated == 'all':
                if not quiet: print "Getting [all] simulated mutations..."
                syntax = "SELECT * FROM %s WHERE is_simulated=1" % (self.mutation_table)
                sim_mutations = pd.read_sql(syntax, self.db_uri)
            else:
                if number_simulated == 'equal':
                    number_simulated = real_mutations.shape[0]
                    if not quiet: print "Getting [%d] simulated mutations... (equal to the total number of real mutations)" % number_simulated
                elif number_simulated == 'average':
                    number_simulated = int(real_mutations[self.donor_id_column].value_counts().mean())
                    if not quiet: print "Getting [%d] simulated mutations... (equal to the average number of real mutations grouped by donor)" % number_simulated
                elif number_simulated == 'max':
                    number_simulated = int(real_mutations[self.donor_id_column].value_counts().max())
                    if not quiet: print "Getting [%d] simulated mutations... (equal to the number of real mutations for the donor with the most)" % number_simulated
                else:
                    if not quiet: print "Getting %d simulated mutations..." % number_simulated
                sys.stdout.flush()
                # Get the mutations 
                sim_ids = pd.read_sql("SELECT %s FROM %s WHERE is_simulated=1" % (self.mutation_table_id, self.mutation_table), self.db_uri)
                # Sample the number requested
                replace = False
                if len(sim_ids) < number_real:
                    if not quiet: print "Fewer possible simulated mutations than requested, sampling with replacement..."
                    replace = True
                sim_ids = sim_ids.sample(number_simulated, replace=replace)
                syntax = "SELECT * FROM %s WHERE %s IN (%s)" % (self.mutation_table, self.mutation_table_id, ", ".join([str(a) for a in list(sim_ids[self.mutation_table_id])]))
                sim_mutations = pd.read_sql(syntax, self.db_uri)
        mutations = pd.concat([real_mutations, sim_mutations])
        mutations = mutations.set_index(self.mutation_table_id)
        self._data = mutations._data
        self.annotation_columns = mutations.columns
        self.mutations_loaded = True
        if not quiet: print "Done"
        return


    def load_features(self, override=False, by=None, feature_categories=None, quiet=None, *args, **kwargs):
        """
        Load feature data that corresponds to previously loaded mutation data. 

        Arguments:
        override (optional; False): If feature data was previously loaded, this function will return immediately after called to prevent data overwrite. This parameter can be set to True to override this behavior.
        by (optional; None): The mutation matrix column to load feature data by. This is useful for breaking up imported data when a large amount of feature data is imported. For example, loading "by" 'donor_id' could break feature data import into reasonably-sized chunks.
        feature_categories (optional; None): A list of database-level feature categories to load (e.g. ["cadd"] to load data just from the "feature_cadd" table). By default, all data is loaded.
        quiet (optional; None): Whether to be verbose in output or not. Defaults to the MutationMatrix set "quiet" parameter. 
        """
        # Allow 'by' shortcuts to be consistent with the load function()
        if by == 'donor':    by = self.donor_id_column
        if by == 'mutation': by = self.mutation_id_column

        quiet = self.quiet if quiet==None else quiet
        ## db_uri
        if self.db_uri==None:
            print "Please select a database using the set_backing_database(database_uri) method."
            return
        # Check to see if this has been done before
        if self.features_loaded and not override:
            print "The MutationMatrix features have already been loaded. Use 'override' set to 'True' to load features again."
            return
        # Check to see that 'by' is either a valid column or None (to just chunk data for encoding as done by _encode_data)
        if by not in list(self.columns) + [None]:
            print "Please choose a valid column to encode by, or in other words, which column you want to group mutations by while encoding. Use 'None' to encode the MutationMatrix index (no grouping)."
            return

        # The final set of encoded mutations 
        loaded_features = None
        feature_categories = feature_categories or self.db_metadata['features'].keys()
        if by!=None:
            item_list = set(self[by])
            # For each item
            for i, item in enumerate(item_list):
                item_mutations = pd.DataFrame(self[self[by]==item])
                if not quiet: print "[%d mutations]" % item_mutations.shape[0]
                # Add mutations features to final dataframe
                by_line = "%s %s [%d/%d]" % (by, str(item), i+1, len(item_list))
                loaded_features = pd.concat([loaded_features, self._load_feature_data(item_mutations, quiet=quiet, feature_categories=feature_categories, by_line=by_line)])
        else:
            mutations = pd.DataFrame(self)
            # Add encoded mutations to final dataframe
            loaded_features = self._load_feature_data(mutations, quiet=quiet, feature_categories=feature_categories)

        # Finalize data and store it back to the MutationMatrix
        self._data = loaded_features._data

        # The table columns have updated, so need to reset the features
        self.feature_categories = feature_categories
        self.set_features()
        self.features_loaded = True
        return


    def encode(self, strategies={}, override=False, features=None, drop_undefined=True, quiet=None, *args, **kwargs):
        """
        Encodes feature data so that it can be used for machine learning. This is particularly important for categorical features, since categories must be made numeric using some predefined strategy. 
        See http://scikit-learn.org/stable/modules/classes.html#module-sklearn.preprocessing for more information
        NOTE: Numeric columns are ignored, categorical encoding defaults to defaults to 'one-hot'.

        Arguments:
        strategies (optional; {}): a dictionary mapping feature (table) name to defined scikitlearn.preprocessing or category_encoders encoder class with a fit_transform() function. 
        override (optional; False): If feature data was previously encoded, this function will return immediately after called to prevent data overwrite. This parameter can be set to True to override this behavior.
        features (optional; None): A list of features to encode, or None to encode all loaded features. 
        drop_undefined (optional; True): Some features have default 'undefined' column values, which can be encoded separately or ignored. When dropping undefined columns, these values are ignored. 
        quiet (optional; None): Whether to be verbose in output or not. Defaults to the MutationMatrix set "quiet" parameter. 
        """
        quiet = self.quiet if quiet==None else quiet
        ## db_uri
        if self.db_uri==None:
            print "Please select a database using the set_backing_database(database_uri) method."
            return
        # Check to see if this has been done before
        if self.encoded and not override:
            print "The MutationMatrix features have already been encoded. Use 'override' set to 'True' to encoded features again."
            return

        final_encoded = pd.DataFrame(self)
        features = features or self.feature_categories
        for i, tbl in enumerate(features):
            if not quiet:
                try:
                    clear_output(wait=True)
                except:
                    pass
                print "%2d/%2d [%3.1f%% complete]  Encoding feature '%s'  %s \r" % (i+1, len(features), 100*((i+1)/float(len(features))), tbl, " "*100)
                sys.stdout.flush()

            # Get the (sub)features of table
            subfeatures = self.db_metadata['features'][tbl]
            # Many features will not have any subfeatures (>1 column) in their feature table, make a singleton list of (sub)features
            if type(subfeatures) != list:
                subfeatures = [subfeatures]
            # For each (sub)feature, determine its type
            for subfeature in subfeatures:
                column = subfeature['column'].lower()
                tbl_type = subfeature['type']
                # If categorical, encode the feature with the given strategy, or use a dummy encoding
                if tbl_type=='category':
                    strat   = 'one-hot'
                    encoder = None
                    encoded = None
                    if tbl in strategies.keys():
                        strat = strategies[tbl]
                    # Use CE encoders for the following
                    if strat in ['one-hot', 'binary']:
                        if strat == 'one-hot':
                            encoder = ce.OneHotEncoder()
                            encoded = encoder.fit_transform(list(final_encoded[column].fillna('undefined')))
                            # Relabel the columns
                            ce_map = dict(encoder.ordinal_encoder.mapping[0]['mapping'])
                            rev_map = dict([(b,a) for a,b in ce_map.items()])
                            new_cols = [rev_map[int(a.split('_')[-1])] for a in list(encoded.columns)]
                            new_cols =  ["%s|%s" % (column, a.replace(' ','_').lower()) for a in new_cols]
                            encoded.columns = new_cols
                            if drop_undefined:
                                encoded = encoded.drop("%s|undefined" % (column), axis=1, errors='ignore')
                        elif strat == 'binary':
                            encoder = ce.BinaryEncoder()
                            encoded = encoder.fit_transform(list(final_encoded[column].fillna('undefined')))
                            encoded.columns = [a.replace('0_',column+'|bit',1) for a in encoded.columns]
                            if drop_undefined:
                                encoded = encoded.drop("%s|undefined" % (column), axis=1, errors='ignore')
                        encoded.index = final_encoded.index
                    # Otherwise default to scikit-learn encoders
                    else:
                        if strat == 'label':
                            encoder = LabelEncoder()
                            encoded = pd.Series(encoder.fit_transform(final_encoded[column]), name=column, index=final_encoded.index)
                        if strat == 'rarity':
                            encoder = dict(final_encoded[column].value_counts()/len(final_encoded[column]))
                            encoder[np.nan] = 0
                            encoded = final_encoded[column].apply(lambda k: encoder[k])
                    # Remove the old data and update with the encoded data
                    final_encoded.drop(column, 1, inplace=True)
                    final_encoded = pd.concat([final_encoded, encoded], axis=1)
                    # Store the encoder for possible future encoding
                    self.feature_transforms[column] = encoder
        self._data = final_encoded._data
        self.set_features()
        self.encoded = True
        if not quiet: print "Done"
        return


    def load_and_encode(self, *args, **kwargs):
        '''Combines the load_mutations(), load_features(), and encode() functions, please see individual help docstrings for more information.'''
        self.load_mutations(*args, **kwargs)
        kwargs.pop('by', None) # Faster NOT to load by in most cases
        self.load_features(*args,  **kwargs)
        self.encode(*args, **kwargs)


    def collapse(self, override=False, by='donor_id', how='mean', quiet=None):
        """
        This will aggregate multiple mutations across a field using a averaging strategy for each group. For example, this function will average all mutation feature values within each donor to create a new MutationMatrix. 

        Arguments:
        override (optional; False): If feature data was collapse, this function will return immediately after called to prevent data overwrite. This parameter can be set to True to override this behavior. Previous collapse data cannot be used, however. 
        by (optional; donor_id): Which column the data should be aggregated upon.
        how (optional; mean): 'mean' or 'median'.
        """
        quiet = self.quiet if quiet==None else quiet
        # Check to see that 'by' is a valid column
        if by not in list(self.columns)+[self.index.name]:
            print "Please choose a valid column to collapse by. Use [MutationMatrix].columns to see valid options"
            return
        
        if how not in ['mean','median']:
            print "Please choose a valid way to collapse data ('mean', 'median')."
            return

        # Check to see if this has been done before
        if self.collapsed and not override:
            print "This MutationMatrix has already been collapsed. Use 'override' set to 'True' to collapse again."
            return

        # Get a list of unique items in the collapse column and iterate over them
        collapsed_mutations = None
        if by==self.index.name:
            item_list = list(set(self.index))
        else:
            item_list = list(set(self[by]))
        
        for i, item in enumerate(item_list):
            if not quiet: 
                try:
                    clear_output(wait=True)
                except:
                    pass
                print "%2d/%2d [%3.1f%% complete]  Collapsing '%s'  %s \r" % (i+1, len(item_list), 100*((i+1)/float(len(item_list))), item, " "*100)
                sys.stdout.flush()
            item_mutations = None
            # Subset the current items data
            if by==self.index.name:
                item_mutations = self[self.index==item]
            else:
                item_mutations = self[self[by]==item]
            # Skip if only one value
            if not item_mutations.shape[0]<2:
                # Otherwise get feature data
                temp = item_mutations[list([by]+list(self.features))].apply(pd.to_numeric, errors='ignore')
                # Group by donor id and calculate using 'how'
                if how=='mean':
                    temp = temp.groupby(by).mean()
                elif how=='median':
                    temp = temp.groupby(by).median()
                # Add the clean collapsed donor mutations to the final dataframe
                collapsed_mutations = pd.concat([collapsed_mutations, temp])
            # For only one mutation
            else:
                item_mutations = item_mutations.set_index(by)
                collapsed_mutations = pd.concat([collapsed_mutations, item_mutations])

        self._data = collapsed_mutations._data
        self.collapsed = True
        self.annotation_columns = pd.Index([])
        if not quiet: print "Done"
        return


    def select_features(self, model=None, n_splits=10, quiet=None):
        """
        Uses a provided model (defaults to a random forest) to perform feature selection with a leave-one-out approach, repeating a desired number of times with data subsets to build a consensus of feature importance. 

        Arguments:
        model (optional; defaults to a random forest): A scikit-learn model to assess performance of each feature in the model.
        n_splits (optional; defaults to 50): The number of models to use to build a feature importance consensus. 
        quiet (optional; defaults to MutationMatrix default): Whether to be verbose or not.
        """
        quiet = self.quiet if quiet==None else quiet
        if model==None:
            print "No model specified, using a random forest classifier."
            model =  RandomForestClassifier(n_estimators=50)


        X, Y = self.normalize2XY()
        features = self.features

        Y_map = {a: b for a,b in enumerate(Y.unique())}
        map_Y = {b: a for a,b in Y_map.iteritems()}
        Y = np.array(Y.apply(lambda k: map_Y[k]))
        X = np.array(X)
        scores = defaultdict(list)
        
        n = 1
        for train_idx, test_idx in ShuffleSplit(n_splits=n_splits, test_size=.25).split(X):
            if not quiet: 
                try:
                    clear_output(wait=True)
                except:
                    pass
                print "%2d/%2d [%3.1f%% complete]  Split %d\r" % (n, n_splits, 100*((n)/float(n_splits)), n)
                sys.stdout.flush()
                n+=1
            X_train, X_test = X[train_idx], X[test_idx]
            Y_train, Y_test = Y[train_idx], Y[test_idx]
            r = model.fit(np.array(X_train), np.array(Y_train))
            acc = r2_score(Y_test, model.predict(X_test))
            for i in range(X.shape[1]):
                X_t = X_test.copy()
                np.random.shuffle(X_t[:, i])
                shuff_acc = r2_score(Y_test, model.predict(X_t))
                scores[features[i]].append((acc-shuff_acc)/acc)
        new_features = sorted([(round(np.mean(score),4), feat) for feat, score in scores.items()], reverse=True)
        if not quiet: print "Done"
        return pd.DataFrame(new_features, columns=['Score', 'Feature'])


    def normalize2XY(self, normalize_options=None, quiet=None):
        """
        Uses the default normalization parameters to make a normalized feature vector matrix (X) and a label vector (Y).

        Arguments:
        normalize_options (optional; defaults to MutationMatrix defaults): The inputer and scaler normalization parameters.
        quiet (optional; defaults to MutationMatrix default): Whether to be verbose or not.
        """
        normalize_options = self.normalize_options if normalize_options == None else normalize_options
        quiet             = self.quiet             if quiet             == None else quiet

        Y = None
        if self.label_column:
            Y = pd.Series(self[self.label_column])
        else:
            print "You should specify a label column before calling normalize_XY"
            return
        X = self[self.features]
        X, imputer, scaler = self._normalize(X)
        X = pd.DataFrame(X)
        X.columns = self.features
        return (X,Y)


    def normalize(self, normalize_options=None, quiet=None, override=False):
        """
        Normalizes the MutationMatrix creating a normalized feature vector matrix and a label vector column as a dataframe.

        Arguments:
        normalize_options (optional; defaults to MutationMatrix defaults): The inputer and scaler normalization parameters.
        quiet (optional; defaults to MutationMatrix default): Whether to be verbose or not.
        override (optional; False): Will repeat the normalization process even if it has already been performed.
        """
        # Set defaults
        normalize_options = self.normalize_options if normalize_options == None else normalize_options
        quiet             = self.quiet             if quiet             == None else quiet

        if override or not self.normalized:
            labels = None
            if self.label_column:
                labels = self[self.label_column]
            else:
                print "You should specify a label column before calling normalize"
                return
            X = self[self.features]
            X, self.imputer, self.scaler = self._normalize(X, as_df=True)
            self.drop(self.features, axis=1, inplace=True)
            self._data = pd.concat([self._data, X], axis=1)
        else:
            print "This MutationMatrix has already been normalized. Use 'override' set to 'True' to normalize again."
        
        self.normalized = True
        return


    def make_model(self, optimize_parameters=False, cross_validate=True, sanity_check=False, cv=10, test_size=0.0, model_type='rf', **model_parameters):
        """
        Performs modeling on a prepared MutationMatrix. Generally speaking, 'prepared' means data has been loaded, encoded, and feature/label columns have been set. 
        By default, modeling is performed with cross validation using 'cv' number of folds and resulting class prediction probabilities and labels are saved to the Mutation Matrix. 
        When using cross validation, no model is generated for future prediction, however, since each fold uses an independently fit model which creates ambiguity as to which one to use, no none are.
        If 'cross_validate' is set to False and 'test_size' is provided, then that portion of data will be withheld for testing and a model will be fit with the remaining (training) data. 
        The model for non cross validated learning is saved to the Mutation Matrix as well as training/testing data.
        This function is best called indirectly using 'random_forest()' or 'support_vector_machine()', but these classifiers can be provided as 'model_type' ('rf', and 'svm' respectively).

        Arguments:
        optimize_parameters (optional; False): Use grid search to find a set optional modeling parameters. This is either applied to the entire dataset in a cross validated fashion ('cv' is specified), or to the training dataset ('cv' is 0).
        cross_validate (optional; True): Whether to test model performance through cross validation using 'cv' number of folds. NOTE: cross-validation only assesses performance within the dataset, it cannot be used to generate predictive models for other data (set to False if you wish to do this).
        sanity_check (optional; False): After modeling, shuffle the labels and remodel to determine if classification matches a null model distribution (i.e. accuracy matches random label guessing). This helps reduce modeling error due to systematic issues with the data such as high class label imbalance. 
        cv (optional; defaults to 10): The number of cross-validation folds to use when modeling.
        test_size (optional; defaults to 0.0): The portion of data to use for testing, specified between 0 and 1. Remaining data is used to build the model.
        model_type (optional; defaults to 'rf'): The type of classifier to use for modeling, either 'rf' for random forest or 'svm' for support vector machine. 
        NOTE: additional model parameters can be provided as key/value parameters. 
        """
        if not self.mutations_loaded:
            print "No mutation data has been loaded into the MutationMatrix, please use load() or load_mutations() before modeling."
            return
        if not self.features_loaded:
            print "No feature data has been loaded into the MutationMatrix, please use load() or load_features() before modeling."
            return 
        if not self.encoded:
            print "Data has not yet been encoded. Please use encode() before modeling."
            return
        if self.label_column==None:
            print "You should specify a label column with set_label_column() before modeling."
            return
        if test_size < 0.0 or test_size >= 1.0:
            print "When specifying a 'test_size', please provide a value between 0 and 1.0."
            return
        
        # Initialize the model
        self.model = self._prepare_model(model_type, **model_parameters)

        # Get the initial data
        X = self[self.features].sort_index()
        Y = self[self.label_column].apply(str).sort_index()

        # Normalize data, keep associated ids until after splitting
        X, self.imputer, self.scaler = self._normalize(X, as_df=True)

        # Split the dataset in testing and training sets if needed
        if test_size>0:
            self.X_train, self.X_test, self.Y_train, self.Y_test = train_test_split(X, Y, test_size=test_size, random_state=0)
        else:
            self.X_train = X
            self.Y_train = Y
            self.X_test  = X
            self.Y_test  = Y

        # Save training ids 
        self.train_ids = self.X_train.index
        #self.X_train = np.array(self.X_train)
        #self.X_test  = np.array(self.X_test)

        # Generate label encoder
        self.le = LabelEncoder()
        self.le = self.le.fit(self.Y_train)
        #self.Y_train = self.le.fit_transform(self.Y_train)

        # If grid search is requested, do it, and update the model with the best parameters
        if optimize_parameters:
            print "Optimizing parameters with %d-fold cross validation." % cv
            if 'param_grid' in model_parameters.keys() and not self.quiet: print "...", model_parameters['param_grid']
            sys.stdout.flush()
            model_parameters.update(self._grid_search(cv=cv, **model_parameters))
            # Re-initiate the model 
            self.model = self._prepare_model(model_type, **model_parameters)
        # The param grid is only used for grid search, which is now done. Remove this to avoid confusion on what model parameters were actually run.
        model_parameters.pop('param_grid', None)

        # Use One-vs-rest classification scheme for multi-class case
        if len(set(self.Y_train))>2:
            print "Multi-class prediction detected, using a one-vs-rest classification strategy."
            sys.stdout.flush()
            self.model = OneVsRestClassifier(self.model)

        if cross_validate == True:
            print "Building a %s using %d-fold cross validation." % (model_type, cv)
            if not self.quiet: print "...", model_parameters
            sys.stdout.flush()
            probs, preds = self._cross_validate(cv=cv)
            self.Y_probabilities = probs
            self.Y_predictions = preds
            self.cv_used = True
        else:
            print "Building a %s model using %0.2f%% of the data" % (model_type, (1.0-test_size)*100)
            if not self.quiet: print "...", model_parameters
            sys.stdout.flush()
            probs, preds = self._split_model()
            self.Y_probabilities = probs
            self.Y_predictions = preds
            self.cv_used = False

        if sanity_check:
            print "Running sanity check by modeling with shuffled labels."
            sys.stdout.flush()
            self._sanity_check(cv=cv)


    def random_forest(self, optimize_parameters=False, cross_validate=True, sanity_check=False, cv=10, test_size=0.0, **model_parameters):
        """
        Performs random forest modeling on a prepared MutationMatrix. Generally speaking, 'prepared' means data has been loaded, encoded, and feature/label columns have been set. 
        By default, modeling is performed with cross validation using 'cv' number of folds and class prediction probabilities and labels are saved to the Mutation Matrix. 
        When using cross validation, no model is generated for future prediction, however, since each fold has an independently fit model creating ambiguity as to which one to use.
        If 'cross_validate' is set to False and 'test_size' is provided, then that portion of data will be withheld for testing and a model will be built with remaining data. 
        The model for non cross validated learning is saved to the Mutation Matrix as well as training/testing data.
        This function is best called indirectly using 'random_forest()' or 'support_vector_machine()', but these classifiers can be provided as model_type.
        Any of the scikit-learn random forest parameters can be passed.

        Arguments:
        optimize_parameters (optional; False): Use grid search to find a set optional modeling parameters. This is either applied to the entire dataset in a cross validated fashion ('cv' is specified), or to the training dataset ('cv' is 0).
        cross_validate (optional; True): Whether to test model performance through cross validation using 'cv' number of folds. NOTE: cross-validation only assesses performance within the dataset, it cannot be used to generate predictive models for other data (set to False if you wish to do this).
        sanity_check (optional; False): After modeling, shuffle the labels and remodel to determine if classification matches a null model distribution (i.e. accuracy matches random label guessing). This helps reduce modeling error due to systematic issues with the data such as high class label imbalance. 
        cv (optional; defaults to 10): The number of cross-validation folds to use when modeling.
        n_estimators (optional; defaults to 40): The number of random forest estimators to use (i.e. forest size). 
        test_size (optional; defaults to 0.0): The portion of data to use for testing, specified between 0 and 1. Remaining data is used to build the model.
        """
        if 'param_grid' not in model_parameters.keys():
            model_parameters['param_grid'] = {
                  "max_depth":         [1, 3, 5, None],
                  "max_features":      [1, .5, 10, 'auto', None],
                  "min_samples_split": [2, 3, 10],
                  "min_samples_leaf":  [2, 3, 10],
                  "bootstrap":         [True, False],
                  "criterion":         ["gini", "entropy"]
                 }
        if 'n_estimators' not in model_parameters.keys():
            model_parameters['n_estimators'] = 40
        self.make_model(optimize_parameters, cross_validate, sanity_check, cv, test_size, model_type='rf', **model_parameters)
    def rf(self, optimize_parameters=False, cross_validate=True, sanity_check=False, cv=10, test_size=0.0, **model_parameters):
        '''see help(MutationMatrix.random_forest)'''
        self.random_forest(optimize_parameters, cross_validate, sanity_check, cv, test_size, **model_parameters)


    def support_vector_machine(self, optimize_parameters=False, cross_validate=True, sanity_check=False, cv=10, test_size=0.0, **model_parameters):
        """
        Performs support vector machine modeling on a prepared MutationMatrix. Generally speaking, 'prepared' means data has been loaded, encoded, and feature/label columns have been set. 
        By default, modeling is performed with cross validation using 'cv' number of folds and class prediction probabilities and labels are saved to the Mutation Matrix. 
        When using cross validation, no model is generated for future prediction, however, since each fold has an independently fit model creating ambiguity as to which one to use.
        If 'cross_validate' is set to False and 'test_size' is provided, then that portion of data will be withheld for testing and a model will be built with remaining data. 
        The model for non cross validated learning is saved to the Mutation Matrix as well as training/testing data.
        This function is best called indirectly using 'random_forest()' or 'support_vector_machine()', but these classifiers can be provided as model_type.
        Any of the scikit-learn SVC parameters can be passed. 

        Arguments:
        optimize_parameters (optional; False): Use grid search to find a set optional modeling parameters. This is either applied to the entire dataset in a cross validated fashion ('cv' is specified), or to the training dataset ('cv' is 0).
        cross_validate (optional; True): Whether to test model performance through cross validation using 'cv' number of folds. NOTE: cross-validation only assesses performance within the dataset, it cannot be used to generate predictive models for other data (set to False if you wish to do this).
        sanity_check (optional; True): After modeling, shuffle the labels and remodel to determine if classification matches a null model distribution (i.e. accuracy matches random label guessing). This helps reduce modeling error due to systematic issues with the data such as high class label imbalance. 
        cv (optional; defaults to 10): The number of cross-validation folds to use when modeling.
        test_size (optional; defaults to None): The portion of data to use for testing, specified between 0 and 1. Remaining data is used to build the model.
        """
        if 'param_grid' not in model_parameters.keys():
            model_parameters['param_grid'] = {
                  "kernel": ('linear', 'rbf'), 
                  "C":      [1, 10]
                  }
        if 'kernel' not in model_parameters.keys():
            model_parameters['kernel'] = 'linear'
        if 'probability' not in model_parameters.keys():
            model_parameters['probability'] = True
        if 'class_weight' not in model_parameters.keys():
            model_parameters['class_weight'] = 'balanced'
        self.make_model(optimize_parameters, cross_validate, sanity_check, cv, test_size, model_type='svm', **model_parameters)
    def svm(self, optimize_parameters=False, cross_validate=True, sanity_check=False, cv=10, test_size=0.0, **model_parameters):
        '''see help(MutationMatrix.support_vector_machine)'''
        self.support_vector_machine(optimize_parameters, cross_validate, sanity_check, cv, test_size, **model_parameters)


    def predict(self, X_df=None):
        """
        Make predictions on a dataframe using a generated model. 

        Arguments:
        X_df (optional; None): If no dataframe is provided, test data at time of modeling will be used. If no test data exists, then training data will be used.

        Returns:
        1) If X_df is provided, X_df with new columns corresponding to prediction labels and populated with classification probabilities.
        2) If X_df is not provided, the actual labels from testing or training data and new columns corresponding to prediction labels and populated with classification probabilities.
        """
        if self.cv_used:
            print "Data was modeled using cross-validation, therefore no model was generated. To see probabilities and predictions for samples when they were apart of the test set, use Y_probabilities and Y_predictions."
            return
        if self.model == None:
            print "No model has been generated yet, please do so with svm(), rf(), or make_model()."
            return

        # Normalize data
        X = None
        if X_df is None and self.X_test is not None:
            X = self.X_test
        elif X_df is None and self.X_test is None:
            print "WARINING: No test data is available for prediction, using training data instead."
            X = self.X_train
        else:
            # Create missing columns and fill with NaN
            missing = pd.DataFrame([], columns=set(self.features).difference(set(X_df.columns)))
            X_df = pd.concat([X_df, missing], axis=1)
            X = X_df[self.features]
            X = self._normalize(X, imputer=self.imputer, scaler=self.scaler, as_df=True)[0]
        
        probabilities = pd.DataFrame(self.model.predict_proba(X))
        probabilities.columns = [str(a) for a in list(self.model.classes_)]
        probabilities = probabilities.reset_index(drop=True)
        
        if X_df is None:
            predictions = pd.concat([pd.Series(self.Y_test), probabilities], axis=1)
            predictions.columns = ["Actual"] + list(predictions.columns[1:])
        else:
            X_df = X_df.reset_index(drop=True)
            predictions = pd.concat([X_df, probabilities], axis=1)
        return predictions


    def show_clusters(self, cmap="Oranges", downsample_n=None):
        """
        Show the MutationMatrix feature data as a clustered heatmap, clustered on both sample and feature.
        NOTE: Cluster dendrograms are not shown, nor is the heatmap legend. 

        Arguments:
        cmap (optional; Oranges): The matplotlib colormap to use to color values.
        downsample_n (optional; None): This function won't work for more than 1,000 samples. In these cases, downsampling can be used to reduce the number of shown samples to less than 1,000.
        """
        if not(self.shape[0]<1000 or (downsample_n and downsample_n<1000)):
            print "Attempting to show a dendrogram for more than 1,000 entries is currently disabled. You can try using the 'downsample_n' parameter with a given integer n < 1,000 to randomly sample n entries."
            return

        Xd = None
        if downsample_n:
            Xd = self.sample(downsample_n)
        else:
            Xd = self
        Yd = list(Xd[self.label_column])
        Xd = Xd[self.features]
        Xd = self._normalize(Xd)[0]
        hm = pd.DataFrame(Xd)
        hm.columns = self.features
        hm.index = Yd

        figsize = self._get_figsize(hm)

        print "Please wait..."
        sys.stdout.flush()
        cg = sns.clustermap(hm, 
                            method='complete', 
                            cmap=cmap, 
                            linewidths=.05, 
                            figsize=figsize
                           )
        cg.ax_row_dendrogram.set_visible(False)
        cg.ax_col_dendrogram.set_visible(False)
        cg.cax.set_visible(False)


    def show_class_predictions(self, as_heatmap=True, cmap="Reds"):
        """
        Generate a table of prediction probabilities with actual and predicted classes, and or as a heatmap. 
        
        Arguments:
        cmap (optional; Reds): The matplotlib colormap to use to color values. 
        as_heatmap (optional; False): Whether to also show this table as a heatmap.

        Returns:
        predictions: The class predictions as a dataframe, if 'as_heatmap' is set to False
        """
        if self.model==None:
            print "You should run a model before making class predictions."
            return

        labels = pd.DataFrame(self.Y_test)
        predictions = self.Y_predictions
        probabilities = self.Y_probabilities
        predictions = pd.concat([labels, predictions, probabilities], axis=1)
        predictions = predictions.rename(columns = {self.label_column:'Actual'})

        if as_heatmap:
            sns.set_style("white")
            sns.set_context("poster")
            figsize = self._get_figsize(predictions)
            fig, ax = plt.subplots()
            # the size of A4 paper
            fig.set_size_inches(figsize)
            shown = predictions.drop(["Predicted"], axis=1).set_index('Actual')
            print "Please wait..."
            sys.stdout.flush()
            ax = sns.heatmap(shown, linewidths=.5, square=True, cmap=cmap)
            ax.set_xlabel("Prediction Probability")
            ax.set_ylabel("Actual")
        else:
            return predictions


    def show_confusion_matrix(self, as_heatmap=True, cmap="Reds", annot=True, normalize=True, **kwargs):
        """
        Show a confusion matrix indicating which samples were misclassified 

        Arguments:
        cmap (optional; Reds): The matplotlib colormap to use to color values. 
        as_heatmap (optional; False): Whether to also show this table as a heatmap. 
        annot (optional; True): Whether to show values inside the heatmap.
        normalize (optional; True): Whether to convert raw counts to percentages.

        Returns:
        confusion: The confusion matrix as a dataframe, if 'as_heatmap' is set to False
        """
        if self.model==None:
            print "You should run a model before making class predictions."
            return

        predictions = self.show_class_predictions(as_heatmap=False)
        confusion = pd.DataFrame(confusion_matrix(predictions['Actual'], predictions['Predicted']))
        confusion.columns = sorted(list(set(predictions['Actual'])))
        confusion.index   = confusion.columns

        # Define annotation text size if not defined
        size = 10
        if "annot_kws" in kwargs.keys():
            if "size" in kwargs["annot_kws"].keys():
                size = kwargs["annot_kws"]["size"]
        else:
            kwargs["annot_kws"] = dict()
        kwargs["annot_kws"]["size"] = size

        if normalize:
            confusion = confusion.div(confusion.sum(axis=1), axis=0)
        if as_heatmap:
            print "Please wait..."
            sys.stdout.flush()
            plt.figure(figsize=self._get_figsize(confusion))
            fmt=".2f" if normalize else "0.0f"
            sns.heatmap(confusion, cmap=cmap, annot=annot, fmt=fmt, square=True, linewidths=.5, **kwargs)
        else:
            return confusion 


    def print_report(self):
        """
        Generate a dataframe of classification performance measures. 
        """
        if self.model==None:
            print "You should run a model before making class predictions"
            return

        confusions = self.show_confusion_matrix(as_heatmap=False, normalize=False)
        FP = confusions.sum(axis=0) - np.diag(confusions)
        FN = confusions.sum(axis=1) - np.diag(confusions)
        TP = pd.Series(np.diag(confusions), dtype='int64', )
        TP.index = FN.index
        TN = confusions.values.sum() - (FP + FN + TP)

        # Sensitivity, hit rate, recall, or true positive rate
        TPR = TP/(TP+FN)
        # Specificity or true negative rate
        TNR = TN/(TN+FP)
        # Precision or positive predictive value
        PPV = TP/(TP+FP)
        # Negative predictive value
        NPV = TN/(TN+FN)
        # Fall out or false positive rate
        FPR = FP/(FP+TN)
        # False negative rate
        FNR = FN/(TP+FN)
        # False discovery rate
        FDR = FP/(TP+FP)

        # Overall accuracy
        ACC = ((TP+TN)/(TP+FP+FN+TN))

        report = pd.DataFrame([FP,FN,TP,TN,TPR,FPR,PPV,NPV,FNR,FDR,ACC]).transpose()
        report.columns = ['FP','FN','TP','TN','TPR','FPR','PPV','NPV','FNR','FDR','ACC']

        # Add means
        means = pd.DataFrame(report.mean()).transpose()
        means.index = ['Mean']
        report = pd.concat([report,means], axis=0)
        
        report = report.round(pd.Series([0,0,0,0,3,3,3,3,3,3,3], index=report.columns))
        return report


    def print_mean_confidences(self):
        """
        Get an idea of how confident the model was at classifying each class. This is defined as how far from random guessing the model was for each class on average.
        """
        labels = pd.DataFrame(self.Y_test)
        probabilities = self.Y_probabilities
        confidences = pd.DataFrame((abs(probabilities-(1/len(labels)))+(1/len(labels))).mean())
        confidences.columns = ['Mean Confidence']
        return confidences


    def classify_predictions(self, include_training=False):
        """
        Classify the predictions as Positive, Negative, True Positive, True Negative, False Positive, and False Negative
        
        Arguments:
        include_training (optional; False): Whether to include the samples used to train the model.
        
        Returns:
        confidence_probs: The classification dataframe for each sample
        """
        if self.model==None:
            print "You should run a model before making class predictions."
            return

        labels = None
        X = None
        if include_training:
            labels = pd.DataFrame(self.Y_train + self.Y_test)
            X = pd.concat([pd.DataFrame(self.X_train), pd.DataFrame(self.X_test)])
        else:
            labels = pd.DataFrame(self.Y_test)
            X = pd.DataFrame(self.X_test)

        predictions = self.show_class_predictions(as_heatmap=False)
        predictions.columns = [str(int(a)) if type(a) in [np.int64, np.float64] else a for a in predictions.columns]
        classes = predictions.columns[2:]

        # Avoid numeric labels
        predictions.columns = [str(int(a)) if type(a) in [np.int64, np.float64] else a for a in predictions.columns]
        if predictions['Actual'].dtype in [np.int64, np.float64]:
            predictions['Actual']=predictions['Actual'].apply(lambda k: str(int(k)))
        if predictions['Predicted'].dtype in [np.int64, np.float64]:
            predictions['Predicted']=predictions['Predicted'].apply(lambda k: str(int(k)))

        confidence_probs = []
        for i,j in predictions.iterrows():
            # The positive case 
            confidence_probs.append({'Type': 'Positive', 'Class': j['Actual'], 'Probability': j[j['Actual']], 'index': i})
            # The negative case 
            for t in set(classes)-set(j['Actual']):
                confidence_probs.append({'Type': 'Negative', 'Class': t, 'Probability': j[t], 'index': i})
            # The true positive case
            if j['Actual']==j['Predicted']:
                confidence_probs.append({'Type': 'True Positive', 'Class': j['Actual'], 'Probability': j[j['Actual']], 'index': i}) 
            else:
                # The false positive case for the predicted class
                confidence_probs.append({'Type': 'False Positive', 'Class': j['Predicted'], 'Probability': j[j['Actual']], 'index': i})
                # The false negative case for the actual class
                confidence_probs.append({'Type': 'False Negative', 'Class': j['Actual'], 'Probability': j[j['Actual']], 'index': i})
                # The true negative for all but actual class
                for t in set(classes)-set((j['Actual'], j['Predicted'])):
                    confidence_probs.append({'Type': 'Negative', 'Class': t, 'Probability': j[t], 'index': i})
        # Convert to dataframe
        confidence_probs = pd.DataFrame(confidence_probs)
        confidence_probs.set_index('index', inplace=True)
        return confidence_probs



    def show_confidence_plot(self, left="True Positive", right="False Positive", left_color="#EEEEEE", right_color="#AACFE5", plot_options=None, title='Classification Probability Distributions'):
        """
        Generates a plot comparing classification distributions for each class, or how confident the model was in its predictions

        Arguments:
        left (optional; True Positive): The distribution to show on the left side of the violin plot. Choices are "True Positive", "True Negative", "False Positive", "False Negative", "Positive", and "Negative".
        right (optional; False Positive): The distribution to show on the right side of the violin plot. Choices are "True Positive", "True Negative", "False Positive", "False Negative", "Positive", and "Negative".
        left_color (optional; #EEEEEE): The color of the left side of the violin plot as a hex code.
        right_color (optional; #AACFE5): The color of the right side of the violin plot as a hex code.
        plot_options (optional; None): Additional plot options to pass to the seaborn violinplot() function. 
        title (optional; Classification Probability Distribution): The title to place a the top of the plot.
        """
        if self.model==None:
            print "You should run a model before making class predictions."
            return

        # Allow passed plot options to superceed default options
        default_options = {
                            'split':      True, 
                            'inner':      'quart',  # or stick
                            'trim':       True,
                            'cut':        0,
                            'saturation': 1,
                            'linewidth':  0.8,
                            'scale':      'width'
                        }
        if plot_options != None:
            for k,v in plot_options.items():
                if k in default_options.keys():
                    default_options[k]=v
        plot_options = default_options

        confidence_probs = self.classify_predictions()
        confidence_probs_plotted = confidence_probs[(confidence_probs['Type']==left) | (confidence_probs['Type']==right)]
        confidence_probs_plotted = confidence_probs_plotted.sort_values(by=['Class','Type'], ascending=[True, False])

        sns.set(style="white")
        sns.set_context("poster", font_scale=1.5, rc={"lines.linewidth": 2})
        plt.figure(figsize=(20, 15))
        g = sns.violinplot(
                        x='Class', 
                        y='Probability', 
                        hue='Type', 
                        data=confidence_probs_plotted, 
                        palette=[left_color, right_color],
                        **plot_options
                      )
        sns.despine()
        plt.xticks(rotation=90)
        _ = plt.ylim(0,1.1)
        plt.xlabel('')
        plt.ylabel('Probability Distribution')
        plt.title(title)
        plt.legend(bbox_to_anchor=(0.25, 0.98), loc="upper left", borderaxespad=0.)


    def show_roc_curves(self, *args, **kwargs):
        '''see help(MutationMatrix.show_curves)'''
        kwargs['metric']='ROC'
        self.show_curves(*args, **kwargs)
    def show_pr_curves(self, *args, **kwargs):
        '''see help(MutationMatrix.show_curves)'''
        kwargs['metric']='PR'
        self.show_curves(*args, **kwargs)

    def show_curves(self, *args, **kwargs):
        """
        Generates receiver operator characteristic (ROC) or Precision Recall (PR) curves for each class and/or cross validation fold, as well as standard deviation confidences. 

        Arguments:
        metric (optional; ROC): The plotting metric, either "ROC" for Receiver Operator Characteristic curves or "PR" for Precision Recall curves.
        title (optional; ): The title for the plot(s).
        cmap (optional; terrain): The matplotlib color map to use for plotting curves for each class.
        return_data (optional; False): Whether x, y, and auc information about curves should be returned.
        styles (optional; None): Custom plotting parameters for the class average curve. 
        class_order (optional; None): If a particular class order is desired when plotting, it can be specified as a list with this parameter.
        show_folds (optional; True): Whether cross validation fold performance should be shown for each class. 
        show_stds (optional; True): Whether cross validation standard deviations should be shown as filled area around the class mean curve. 
        separate (optional; True): Whether separate curves should be shown for each class.
        minimal (optional; True): Whether minimal plotting should be done (e.g. don't distinguish between folds and their auc values using color).
        
        Returns:
        {'xs':xs, 'ys':ys, 'aucs':curve_aucs}: The x and y coordinates for each class ROC/PR curve, as well as corresponding AUCs
        """
        
        # Load defaults
        metric       = kwargs.pop('metric', 'ROC')
        title        = kwargs.pop('metric', '')
        cmap         = kwargs.pop('cmap', 'terrain')
        return_data  = kwargs.pop('return_data', False)
        styles       = kwargs.pop('styles', None)
        class_order  = kwargs.pop('class_order', None)
        show_folds   = kwargs.pop('show_folds', True)
        show_stds    = kwargs.pop('show_stds', True)
        separate     = kwargs.pop('separate', True)
        minimal      = kwargs.pop('minimal', True)


        if self.model==None:
            print "You should run a model before plotting curves"
            return

        y_act   = self.Y_test.sort_index()
        y_probs = self.Y_probabilities.sort_index()
        # Check that all indices match
        if not all([a==b for a, b in zip(list(y_act.index), list(y_probs.index))]):
            print "ERROR: Actual and predicted probability sample indices do not match"
            return
        
        classes  = y_probs.columns
        classes_ = classes
        if len(classes)==2:
            if 'True' in classes or True in classes:
                classes_ = ['True']
            else:
                classes_ = classes[1]

        y_bin = pd.DataFrame(label_binarize(y_act, classes=classes), columns=classes_, index=y_act.index)
        if len(classes)==2:
            y_bin  = pd.concat([abs(y_bin-1), y_bin], axis=1)
            y_bin.columns = ['False', 'True']


        if class_order:
            if len(set(class_order).difference(set(classes)))!=0:
                print "Please only provide classes that exist in the model when specifying class_order"
                return
            classes = class_order

        # Compute ROC curve and ROC area for each class
        x = dict()
        y = dict()
        curve_aucs = dict()
        mean_xs = np.linspace(0, 1, 100)

        sns.set(style="white")
        sns.set_context("poster", font_scale=2, rc={"lines.linewidth": 5})
        colors = self._get_colors(cmap=cmap, n=len(classes))

        # Figure waaay to busy if not separating, make sure show_folds is off
        if not separate:
            show_folds=False
            show_stds=False
            plt.figure(figsize=(15, 10))

        # Iterate over classes
        for i,c in enumerate(classes):
            if separate:
                plt.figure(figsize=(15, 10))
            
            # Initialize ys and curve aucs for this class
            y[c] = dict()
            curve_aucs[c] = dict()
            
            # In case only one model was fit
            if self.cv_usage is None:
                folds = [pd.Index(self.Y_test.index)]
            else:
                folds = self.cv_usage
            
            # Iterate over folds, or just the single dataset (pretends to be fold 0)
            for f,f_ixs in enumerate(folds):
                if metric=='ROC':
                    xs, ys, _ = roc_curve(y_bin.loc[f_ixs,c], y_probs.loc[f_ixs,c])
                    y[c][f] = interp(mean_xs, xs, ys)
                    y[c][f][0] = 0.0
                    curve_aucs[c][f] = auc(xs, ys)
                else: #metric=='PR'
                    xs, ys, _ = precision_recall_curve(y_bin.loc[f_ixs,c], y_probs.loc[f_ixs,c])
                    y[c][f] = interp(mean_xs, xs, ys)
                    curve_aucs[c][f] = average_precision_score(y_bin.loc[f_ixs,c], y_probs.loc[f_ixs,c])
                if show_folds:
                    if minimal:
                        plt.plot(xs, ys, lw=1, alpha=0.5, color=colors[i])
                    else:
                        plt.plot(xs, ys, lw=1, alpha=0.9, label='%s: fold %d (AUC = %0.2f)' % (c, f+1, curve_aucs[c][f]))

            mean_ys = np.array(pd.DataFrame(y[c]).mean(axis=1))
            mean_ys[-1] = 1.0
            mean_auc = auc(mean_xs, mean_ys)
            std_auc = pd.Series(curve_aucs[c]).std()
            try:
                plt.plot(mean_xs, mean_ys, label=r'%s (AUC = %0.2f $\pm$ %0.2f)' % (c, mean_auc, std_auc), **styles[c])
            except:
                plt.plot(mean_xs, mean_ys, color=colors[i], alpha=.75, lw=3, label=r'%s (AUC = %0.2f $\pm$ %0.2f)' % (c, mean_auc, std_auc))

            std_ys = np.array(pd.DataFrame(y[c]).std(axis=1))
            ys_upper = np.minimum(mean_ys + std_ys, 1)
            ys_lower = np.maximum(mean_ys - std_ys, 0)
            if show_stds:
                plt.fill_between(mean_xs, ys_lower, ys_upper, color=colors[i], alpha=.2, label=r'%s $\pm$ 1 std. dev.' % c)

            if separate:
                # Add labels and clean up the graph
                if metric=='ROC':
                    plt.plot([0, 1], [0, 1], 'k--', lw=2, label="Guessing")
                    plt.xlabel('False Positive Rate')
                    plt.ylabel('True Positive Rate')
                    plt.legend(loc="lower right", prop={'size': 16})
                elif metric=='PR':
                    plt.plot([0, 1], [0.5, 0.5], 'k--', lw=2, label="Guessing")
                    plt.xlabel('Recall')
                    plt.ylabel('Precision')
                    plt.legend(loc="lower left", prop={'size': 16})
                plt.xlim([0.001, 1.001])
                plt.ylim([0.001, 1.001])
                plt.title(title)
                plt.show()
        if not separate:
            # Add labels and clean up the graph
            if metric=='ROC':
                plt.plot([0, 1], [0, 1], 'k--', lw=2, label="Guessing")
                plt.xlabel('False Positive Rate')
                plt.ylabel('True Positive Rate')
                plt.legend(loc="lower right", prop={'size': 12})
            elif metric=='PR':
                plt.plot([0, 1], [0.5, 0.5], 'k--', lw=2, label="Guessing")
                plt.xlabel('Recall')
                plt.ylabel('Precision')
                plt.legend(loc="lower left", prop={'size': 12})
            plt.xlim([0.001, 1.001])
            plt.ylim([0.001, 1.001])
            plt.title(title)
            plt.show()

        if return_data:
            return {'xs':mean_xs, 'ys':y, 'aucs':curve_aucs}


    def show_feature_importances(self, how="boxplot", return_data=False, order=False):
        """
        Will show a boxplot, barplot, or table showing how important each feature was for classification.
        NOTE: This only applies to non-cross-validated models

        Arguments:
        how (optional; boxplot): how the data should be plotted or returned. Options are ["boxplot", "barplot", "table"].
        return_data (optional; False): If plot data should be returned when "boxplot" or "barplot" are used.
        order (optional; False): Whether or not features should be ordered by importance.

        Returns:
        A table when "table" is used for "how", or a stacked dataframe of plot values when "boxplot" or "barplot" are use for "how" and "return_data" is True.
        """
        if self.cv_used:
            print "Cross validation was used to make predictions, therefore individual model feature importances were not retained. Please make a new model without cross-validation if you'd like to measure feature importances."
            return
        if self.model==None:
            print "You should run a model before making class predictions"
            return

        fws = None
        if type(self.model)==OneVsRestClassifier:
            for est in self.model.estimators_:
                try:
                    fws = pd.concat([fws, pd.DataFrame(est.feature_importances_).transpose()], axis=0)
                except AttributeError:
                    fws = pd.concat([fws, pd.DataFrame(est.coef_)], axis=0)
            fws.columns = self.features
            fws.index = self.model.classes_
        else:
            try:  #RF
                imp = pd.DataFrame(self.model.feature_importances_)
                fws = pd.concat([imp, imp], axis=1).transpose()
            except AttributeError:  # SVM
                imp = pd.DataFrame(self.model.coef_)
                fws = pd.concat([imp, imp], axis=0)
            fws.columns = self.features
            fws.index = self.model.classes_
            how = 'barplot' if how=='boxplot' else how

        if how=="table":
            return fws

        stack = pd.DataFrame(fws.stack())
        stack.columns=['Importance Value']
        stack['Feature'] = [s[1] for s in stack.index]
        stack['Class']  = [s[0] for s in stack.index]

        # Order by importance if requested
        if order==True:
            stack = stack.sort_values(by='Importance Value', ascending=False)
        else:
            stack = stack.sort_index()

        # Plot
        sns.set(style="dark")
        sns.set_context("poster", font_scale=1.5, rc={"lines.linewidth": 2})

        colors = sns.cubehelix_palette(rot=-.3, light=1)

        sns.set_style("white")
        #sns.set_style("whitegrid", {
        #    "ytick.major.size": 1.0,
        #    "xtick.major.size": 1.0,
        #    'grid.linestyle': '--'
        # })

        fig, ax = plt.subplots()
        fig.set_size_inches(45, 10)
        if how=="byclass":
            sns.stripplot(x='Feature', y='Importance Value', hue='Class', data=stack, jitter=False, alpha=.85, size=10)
        elif how=="barplot":
            sns.barplot(x='Feature', y='Importance Value', data=stack)
        else: #how=="boxplot"
            sns.boxplot(x='Feature', y='Importance Value', data=stack)
        plt.title("Model Feature Importances", fontsize=20)
        plt.xticks(rotation=90, fontsize=12)
        sns.despine()

        if return_data:
            return stack


    def save_matrix(self, filename="MutationMatrix.pkl"):
        """
        Save the entire MutationMatrix to the file provided by "filename".
        """
        joblib.dump(self, filename)

    def save_model(self,  filename="MutationMatrixModel.pkl"):
        """
        Save just the model, imputation/scaling method, used features, and label column to the file provided by "filename".
        """
        with open(filename, 'wb') as f:
            dill.dump([
                        self.features,
                        self.label_column,
                        self.imputer,
                        self.scaler,
                        self.model,
                        self.normalize_options,
                      ], f)

    def load_model(self,  filename="MutationMatrixModel.pkl"):
        """
        Load a previously used model, imputation/scaling method, used features, and label column from the file provided by "filename".
        """
        with open(filename, 'rb') as f:
            data = dill.load(f)
            self.features             = data[0]
            self.label_column         = data[1]
            self.imputer              = data[2]
            self.scaler               = data[3]
            self.model                = data[4]
            self.normalize_options    = data[5]


    ###### Below are internal helper functions that should not be called directly. ########


    def _get_db_column_type(self, table, column):
        """ get the column data type (int or char) from a column in the backing database table """
        db = urlparse(self.db_uri).path.strip('/')
        syntax = "SELECT DATA_TYPE FROM INFORMATION_SCHEMA.COLUMNS WHERE TABLE_SCHEMA = '%s' AND TABLE_NAME = '%s' AND COLUMN_NAME = '%s'" % (db, table, column)
        type_ = pd.read_sql(syntax, self.db_uri)['DATA_TYPE'][0]
        if 'int' in type_:
            return 'int'
        else:
            return 'char'


    def _get_colors(self, cmap="Reds", n=8, white_to_gray=True):
        cmap = cm.get_cmap(cmap, n)
        colors = [rgb2hex(cmap(i)[:3]) for i in range(cmap.N)]
        if white_to_gray:
            colors = ["#888888" if c=="#ffffff" else c for c in colors]
        return colors


    def _load_feature_data(self, mutations, quiet=None, feature_categories=None, by_line=None, *args, **kwargs):
        quiet = self.quiet if quiet==None else quiet
        if feature_categories==None:
            print "You must specify a list of feature categories (feature tables) to load feature data from if calling _load_feature_data manually."
            return

        ids = list(mutations.index)
        for i, tbl in enumerate(feature_categories):
            if not quiet:
                try:
                    clear_output(wait=True)
                except:
                    pass
                if by_line:
                    print by_line
                print "%2d/%2d [%-3.1f%% complete]  Loading feature '%s'  %s \r" % (i+1, len(feature_categories), 100*((i+1)/float(len(feature_categories))), tbl, " "*100)
                sys.stdout.flush()
            # To temporarily store chunked mutations 
            chunk_mutations = None

            for i in xrange(0, len(ids), self.chunk_size):
                # The current chunks ids
                chunk_ids = [str(a) for a in ids[i:(i+self.chunk_size-1)]]
                # Convert the ids to a MySQL like search string, depending on the table key type
                syntax = "SELECT * FROM feature_%s WHERE %s IN (%s)" % (tbl, self.mutation_table_id, ", ".join(chunk_ids))
                temp   = pd.read_sql(syntax, self.db_uri)
                # Make sure the join ids are ints for the encoded_mutations merge (otherwise get nothing but NaNs!)
                temp[self.mutation_table_id] = temp[self.mutation_table_id].astype(int)
                chunk_mutations = pd.concat([chunk_mutations, temp])
            chunk_mutations = chunk_mutations.set_index(self.mutation_table_id)
            mutations = mutations.merge(chunk_mutations, how='left', left_index=True, right_index=True)
        if not quiet: print "Done"
        return mutations


    def _normalize(self, X, normalize_options=None, quiet=None, imputer=None, scaler=None, as_df=False):
        # Set defaults
        normalize_options = self.normalize_options if normalize_options == None else normalize_options
        quiet             = self.quiet             if quiet             == None else quiet

        # Get input options
        nan_strat    = normalize_options['nan_strat']
        scaler_strat = normalize_options['scaler_strat']

        # Check inputs
        if nan_strat not in ('zero','mean','median', 'most_frequent'):
            print "Unknown NaN imputation strategy, please use 'zero', 'mean', 'median', or 'most_frequent'"
            return
        if scaler_strat not in ('mms', 'standard'):
            print "Unknown scaler strategy, please use 'mms' or 'standard' (z-score)"
            return 

        # Store dataframe information if requested
        if as_df: 
            X_idxs = X.index
            X_cols = X.columns
        # Issues with nans between Pandas DataFrame and Numpy array, but this should correct problems downstream
        X = np.array(pd.DataFrame(X).apply(pd.to_numeric, errors='coerce'))

        # Deal with all zero columns
        if not quiet: print "Normalizing data."
        if not quiet: print "... Columns with all NaN values will be set to 0."
        X[:, np.all(pd.isnull(X), axis=0)] = 0

        # Deal with remaining zeros
        if not quiet: print "... Imputing remaining NaNs using the '%s' strategy." % nan_strat
        if imputer == None:
            if nan_strat=='zero':
                imputer = np.nan_to_num
                X = np.nan_to_num(X)
            else: 
                imputer = Imputer(missing_values='NaN', strategy=nan_strat, axis=0)
                X = imputer.fit_transform(X)
        elif imputer == np.nan_to_num:
            X = np.nan_to_num(X)
        else:
            X = imputer.transform(X)

        # Scale values
        if not quiet: print "... Scaling values with the '%s' strategy." % scaler_strat
        if scaler == None:
            if scaler_strat =='mms':
                scaler = MinMaxScaler().fit(X)
            elif scaler_strat=='standard':
                scaler = StandardScaler().fit(X)
        X = scaler.transform(X)

        # Convert back to dataframe if requested
        if as_df:
            X = pd.DataFrame(X, index=X_idxs, columns=X_cols)

        return (X, imputer, scaler)


    def _grid_search(self, cv=None, **model_parameters):
        if self.X_train is None or self.Y_train is None:
            print "Training data must be specified before running this function. Try calling a modeling function first."
            return 

        param_grid = None
        if 'param_grid' in model_parameters.keys():
            param_grid = model_parameters['param_grid']
        else:
            print "To use grid search, please provide a dictionary of possible parameter values."
            return {}

        # run grid search
        grid_search = GridSearchCV(self.model, param_grid, cv=cv, n_jobs=self.number_cpus)
        start = time.time()
        grid_search.fit(self.X_train, self.Y_train)
        stop = time.time()

        if not self.quiet: print "... GridSearchCV took %.2f seconds." % (stop-start)
        if not self.quiet: print "...", grid_search.best_params_ 
        #print grid_search.best_score_
        return grid_search.best_params_


    # Checks the sanity of a model by randomizing the labels and remodeling
    def _sanity_check(self, cv=5):
        if self.label_column==None:
            print "You should specify a label column and run a model before attempting a sanity check of it"
            return
        if self.model==None:
            print "You should train a model before attempting a sanity check of it"
            return
        model = deepcopy(self.model)
        new_labels = list(deepcopy(self.Y_train))
        if not self.quiet: print "... Shuffling labels"
        shuffle(new_labels)

        scores = cross_val_score(model, self.X_train, new_labels, cv=cv, n_jobs=self.number_cpus)
        print "... Accuracy: %0.2f (+/- %0.2f)" % (scores.mean(), scores.std() * 2)
        print "... Expected by chance: %.2f" % (1./len(set(self.Y_train)))


    def _cross_validate(self, cv=5):
        # Define the possible encoded label classes
        encoded_labels = sorted(set(self.le.transform(self.Y_train)))
        # Define the cross validation 
        cv = StratifiedKFold(n_splits=cv)
        # To store class prediction probabilities when example is in the test set
        probabilities = None
        # Used to store the final predictions
        predictions = None
        # To store what fold each test example was predicted in (by index)
        cv_usage = []
        # Used to store the fraction of correctly predicted classes
        scores = []

        for tr_ixs, te_ixs in cv.split(self.X_train, self.Y_train):
            x_tr = self.X_train.iloc[tr_ixs]
            x_te = self.X_train.iloc[te_ixs]
            y_tr = self.Y_train.iloc[tr_ixs]
            y_te = self.Y_train.iloc[te_ixs]
            
            # Make sure at least one of each class is present, or quit
            if set(self.le.transform(y_tr)).difference(encoded_labels) != set():
                print "WARNING: During cross-validation, one of the folds did not receive at least one example for every class, skipping this fold."
                continue
            # Clone the model 
            clf = clone(self.model)
            # Fit and predict probabilities, predictions, and score
            probas_ = clf.fit(x_tr, y_tr).predict_proba(x_te)
            preds_ = map(lambda k: encoded_labels[k], probas_.argmax(axis=1))
            sc_ = [1 if a==b else 0 for a,b in zip(preds_, self.le.transform(y_te))]
            
            # Store results from this fold
            probabilities = pd.concat([probabilities, pd.DataFrame(probas_, index=x_te.index)])
            predictions = pd.concat([predictions, pd.DataFrame(self.le.inverse_transform(preds_), index=x_te.index)])
            scores.append(sum(sc_)/float(len(sc_)))

            # Store indices used in this fold
            cv_usage.append(x_te.index)
        # Clean up the probability dataframe
        probabilities.columns = self.le.inverse_transform(encoded_labels)
        probabilities.sort_index(inplace=True)
        # Clean up predictions dataframe 
        predictions.columns = ["Predicted"]
        predictions.sort_index(inplace=True)
        scores = pd.Series(scores)
        # Save CV usage
        self.cv_usage = cv_usage
        print "... Accuracy: %0.2f (+/- %0.2f)" % (scores.mean(), scores.std() * 2)
        print "... Expected by chance: %.2f" % (1./len(set(self.Y_train)))
        return (probabilities, predictions)


    def _split_model(self):
        self.model.fit(self.X_train, self.Y_train)
        encoded_labels = sorted(set(self.le.transform(self.Y_train)))
        probabilities  = self.model.predict_proba(self.X_test)
        predictions    = self.le.inverse_transform(probabilities.argmax(axis=1))
        # Clean up the probability dataframe
        probabilities         = pd.DataFrame(probabilities)
        probabilities.index   = self.X_test.index
        probabilities.columns = self.le.inverse_transform(encoded_labels)
        probabilities.sort_index(inplace=True)
        # Clean up predictions dataframe 
        predictions         = pd.DataFrame(predictions)
        predictions.index   = self.X_test.index
        predictions.columns = ["Predicted"]
        predictions.sort_index(inplace=True)
        return (probabilities, predictions)


    def _prepare_model(self, model_type, **model_parameters):
        if model_type =='rf':
            argnames = set(inspect.getargspec(RandomForestClassifier.__init__)[0])
            kwargs = {k: v for k, v in model_parameters.iteritems() if k in argnames}
            model = RandomForestClassifier(**kwargs)
        elif model_type == 'svm':
            argnames = set(inspect.getargspec(svm.SVC.__init__)[0])
            kwargs = {k: v for k, v in model_parameters.iteritems() if k in argnames}
            model = svm.SVC(**kwargs)
        else:
            print "Only MutationMatrix random forests and support vector machines are supported at this time."
            return None
        return model


    def _get_figsize(self, df):
        (x, y) = (0,0)
        if df.shape[1]>df.shape[0]:
            ar = df.shape[0]/float(df.shape[1])
        else:
            ar = df.shape[1]/float(df.shape[0])
        scale = 0
        while scale*ar < 12 or (x<10 and y<10):
            scale+=1
            (x, y) = (scale*df.shape[1]/1000., scale*df.shape[0]/1000.)
        # May over shoot plotting size, readjust if needed
        if x > 655:
            f = 655./x
            (x, y) = (f*x,  f*y)
        if y > 655:
            f = 655./y
            (x, y) = (f*x,  f*y)

        return (x, y)

def load_matrix(filename="MutationMatrix.pkl"):
    """
    Load a previously saved MutationMatrix from the file provided by "filename".
    """
    return joblib.load(filename)


